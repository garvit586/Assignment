{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the model sam-2 and installing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/segment-anything-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd segment-anything-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Lenovo/Documents/daily_reports/sam-2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file:///C:/Users/Lenovo/Documents/daily_reports/sam-2 does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -e \".[demo]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statetement 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,glob,shutil\n",
    "import matplotlib.patches as patches\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = r\"C:\\Users\\Lenovo\\Downloads\\CMU10_3D\\CMU10_3D\\data_2D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sam_model():\n",
    "    checkpoint = r\"C:\\Users\\Lenovo\\Documents\\daily_reports\\sam-2\\sam2_hiera_tiny.pt\"\n",
    "    model_cfg = \"sam2_hiera_t.yaml\"\n",
    "    predictor_prompt = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint, device='cpu'))\n",
    "    sam2 = build_sam2(model_cfg, checkpoint, device='cpu', apply_postprocessing=False)\n",
    "    mask_generator = SAM2AutomaticMaskGenerator(sam2)\n",
    "    return mask_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_first_image_and_mask(image_name, image_folder, mask_folder):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    mask_path = os.path.join(mask_folder, image_name.replace(\".jpg\", \"_1_gt.png\"))\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load mask as grayscale\n",
    "    \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_sam2(mask_generator, image, mask):\n",
    "    # Pass the image through SAM2\n",
    "    masks = mask_generator.generate(image)\n",
    "    \n",
    "    filtered_masks = [m for m in masks if m['area'] > 500]  # Filter small masks\n",
    "    \n",
    "    return filtered_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_masks_on_images(mask_generator, object_type, image_folder):\n",
    "    predictions = {}\n",
    "    \n",
    "    images = [f for f in os.listdir(image_folder) if f.startswith(object_type) and f.endswith(\".jpg\")]\n",
    "    \n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        predicted_masks = mask_generator.generate(image)\n",
    "        \n",
    "        filtered_masks = [m for m in predicted_masks if m['area'] > 500]  \n",
    "        predictions[image_name] = filtered_masks\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statement 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_bounding_box(mask):\n",
    "    binary_mask = (mask > 0).astype(np.uint8)\n",
    "    x, y, w, h = cv2.boundingRect(binary_mask)\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_masks_to_bounding_boxes(predicted_masks):\n",
    "    predicted_boxes = {}\n",
    "    \n",
    "    for image_name, mask in predicted_masks.items():\n",
    "        x, y, w, h = mask_to_bounding_box(mask)\n",
    "        predicted_boxes[image_name] = [(x, y, w, h)]\n",
    "    \n",
    "    return predicted_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statement 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) between two bounding boxes.\n",
    "    \"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    boxAArea = boxA[2] * boxA[3]\n",
    "    boxBArea = boxB[2] * boxB[3]\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(image_folder, object_type):\n",
    "    \"\"\"\n",
    "    Load the ground truth bounding boxes from mask files for the object type.\n",
    "    \"\"\"\n",
    "    mask_files = sorted([f for f in os.listdir(image_folder) if f.startswith(object_type) and f.endswith(\"_1_gt.png\")])\n",
    "    \n",
    "    ground_truth_boxes = {}\n",
    "    \n",
    "    for mask_name in mask_files:\n",
    "        mask_path = os.path.join(image_folder, mask_name)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        x, y, w, h = mask_to_bounding_box(mask)\n",
    "        ground_truth_boxes[mask_name] = (x, y, w, h)\n",
    "    \n",
    "    return ground_truth_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(predictions, ground_truths):\n",
    "    \"\"\"\n",
    "    Evaluate the predicted bounding boxes against ground truth using IoU.\n",
    "    \"\"\"\n",
    "    iou_threshold = 0.5\n",
    "    num_correct = 0\n",
    "    num_total = len(ground_truths)\n",
    "    \n",
    "    for image_name, predicted_boxes in predictions.items():\n",
    "        gt_box = ground_truths.get(image_name.replace(\".jpg\", \"_1_gt.png\"))\n",
    "        \n",
    "        for pred_box in predicted_boxes:\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            if iou > iou_threshold:\n",
    "                num_correct += 1\n",
    "                break\n",
    "    \n",
    "    accuracy = num_correct / num_total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define object types\n",
    "    object_types = [\"can_chowder\", \"can_soymilk\", \"can_tomatosoup\", \"carton_oj\", \n",
    "                    \"carton_soymilk\", \"diet_coke\", \"hc_potroastsoup\", \n",
    "                    \"juicebox\", \"rice_tuscan\", \"ricepilaf\"]\n",
    "\n",
    "    # Folder containing all images\n",
    "    all_images_folder = \"C:\\Users\\Lenovo\\Downloads\\CMU10_3D\\CMU10_3D\\data_2D\"\n",
    "    \n",
    "    for object_type in object_types:\n",
    "        # Paths to the first image and mask for each object type\n",
    "        first_image_path = f\"{all_images_folder}/{object_type}_000001.jpg\"\n",
    "        first_mask_path = f\"{all_images_folder}/{object_type}_000001_1_gt.png\"\n",
    "        \n",
    "        print(f\"Processing {object_type}...\")\n",
    "        mask_generator = load_sam_model()\n",
    "\n",
    "        predicted_masks = predict_masks_on_images(mask_generator, object_type, all_images_folder)\n",
    "        \n",
    "        predicted_boxes = convert_masks_to_bounding_boxes(predicted_masks)\n",
    "        \n",
    "        ground_truth_boxes = load_ground_truth(all_images_folder, object_type)\n",
    "        \n",
    "        accuracy = evaluate_predictions(predicted_boxes, ground_truth_boxes)\n",
    "        print(f\"Detection Accuracy for {object_type} (IoU > 0.5): {accuracy * 100:.2f}%\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
